{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c037a62d",
   "metadata": {},
   "source": [
    "## Morning practical 1 day 3\n",
    "\n",
    "Hi there. It could well be that your head is still reeling from the explanation of backpropagation. While it's a simple idea at its core, it can not seem that way at first. It helps to learn about it from different angles. For that reason, this practical will be devoid of any programming. Rather, you'll be watching 2 videos and reading about backpropagation. \n",
    "\n",
    "The reading part can contain some parts that don't make much sense currently. You can skip what you don't understand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b7b71d",
   "metadata": {},
   "source": [
    "## Material to watch and read\n",
    "\n",
    "The videos are the next two videos in the 3Blue1Brown series. They detail very nicely how backpropagation works:\n",
    "\n",
    "* [Video 1](https://www.youtube.com/watch?v=Ilg3gGewQ5U)\n",
    "* [Video 2](https://www.youtube.com/watch?v=tIeHLnjs5U8)\n",
    "\n",
    "The reading material is chapter 2 from the free neural networks and deep learning e-book, which I highly recommend for an understandable foray into the particulars of neural networks:\n",
    "\n",
    "* http://neuralnetworksanddeeplearning.com/chap2.html\n",
    "\n",
    "**Note: you don't need to do the exercises that are mentioned in the text, i.e. I am not expecting you to give proofs of the fundamental equations of backpropagation! This is just to better [grok](https://en.wikipedia.org/wiki/Grok) the concept of backpropagation.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddd7054",
   "metadata": {},
   "source": [
    "## Optional extra materials\n",
    "\n",
    "You can always read more chapters from the neural networks and deep learning e-book. Additionally, you can look at the StatQuest neural network videos:\n",
    "https://www.youtube.com/watch?v=IN2XmBhILt4&list=PLblh5JKOoLUIxGDQs4LFFD--41Vzf-ME1&index=4. More materials are in the reader."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bcc8cf",
   "metadata": {},
   "source": [
    "## What I want you to remember here:\n",
    "* That we need backpropagation because there is no so-called closed-form solution to optimising a neural net: because of its sequential nature, we have to transport the error we can measure with the cost function at the output back to earlier layers to adjust their weights and biases\n",
    "* An understanding of what backpropagation wants to do: it's all just taking steps along partial derivatives, but to do that we need to transport the error back through layers. We (ab)use the chain rule of differentiation for this.\n",
    "\n",
    "## The end\n",
    "\n",
    "Congratulations, you've watched some videos and read a text. Master level education right there! You can move on immediately to the next practical to start implementing backpropagation. But not before you've done the\n",
    "\n",
    "## Survey\n",
    "That's right, here goes: [click](https://docs.google.com/forms/d/e/1FAIpQLSc7EaTfnz2UNyN5-2sAmwsdN6bfzzLweedsXhyabbDUye_Z5g/viewform?usp=sf_link)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
